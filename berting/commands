python run_lang_model.py \
--data_dir=/home/ubuntu/fakenews/data/train \
--model_type=bert \
--model_name_or_path=/home/ubuntu/results/duplicated_512_2e-5 \
--task_name=fn \
--output_dir=/home/ubuntu/results/duplicated_512_2e-5 \
--max_seq_length=512 \
--do_train \
--evaluate_during_training \
--gradient_accumulation_steps=4 \
--cache_dir=/home/ubuntu/pretrained_models \
--overwrite_output_dir \
--per_gpu_train_batch_size=8 \
--per_gpu_eval_batch_size=8 \
--num_train_epochs=1.0 \
--logging_steps=25 \
--save_steps=100 \
--learning_rate=2e-5 \
--run_name=runs/duplicated_512_2e-5


