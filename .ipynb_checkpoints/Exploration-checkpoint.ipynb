{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/mohamedkhodeir/.cache/torch/hub/huggingface_pytorch-pretrained-BERT_master\n",
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
      "100%|██████████| 213450/213450 [00:03<00:00, 58028.97B/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-pretrained-BERT', 'bertTokenizer', 'bert-base-cased', do_basic_tokenize=False)\n",
    "\n",
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Who',\n",
       " 'was',\n",
       " 'Jim',\n",
       " 'He',\n",
       " '##nson',\n",
       " '?',\n",
       " '[SEP]',\n",
       " 'Jim',\n",
       " 'He',\n",
       " '##nson',\n",
       " 'was',\n",
       " 'a',\n",
       " 'puppet',\n",
       " '##eer',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/mohamedkhodeir/.cache/torch/hub/huggingface_pytorch-pretrained-BERT_master\n",
      "100%|██████████| 313/313 [00:00<00:00, 124946.91B/s]\n",
      "100%|██████████| 435779157/435779157 [02:06<00:00, 3458177.72B/s]\n"
     ]
    }
   ],
   "source": [
    "### Get the hidden states computed by `bertModel`\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "model = torch.hub.load('huggingface/pytorch-pretrained-BERT', 'bertModel', 'bert-base-cased')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0671, -0.0819, -0.3849,  ...,  0.2479,  0.8418,  0.5378],\n",
       "         [-0.0828, -0.2384,  0.3622,  ..., -0.0386, -0.5637,  0.1459],\n",
       "         [ 0.0357, -0.1931,  0.3957,  ...,  0.4133, -0.1263, -0.0303],\n",
       "         ...,\n",
       "         [ 0.1778,  0.0921, -0.0885,  ...,  0.6259, -0.3713,  0.0748],\n",
       "         [ 0.0062, -0.4483, -0.4176,  ...,  0.1641, -0.1112, -0.0908],\n",
       "         [ 0.3182, -0.0281, -0.4652,  ...,  0.5634,  1.3185,  0.6513]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(20, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.matmul(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7511, 1.0024, 0.9575, 0.7957, 1.2212])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7511, 1.0024, 0.9575, 0.7957, 1.2212])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(a.t(), b[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0657, 1.4831, 1.4765, 0.9044, 1.3662])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0657, 1.4831, 1.4765, 0.9044, 1.3662])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(a.t(), b[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1788, 1.3801, 1.4125, 1.0409, 1.2373])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1788, 1.3801, 1.4125, 1.0409, 1.2373])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(a.t(), b[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = torch.rand(*[10, 32, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = torch.rand(*[150, 32, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.rand(*[200,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_doc = torch.matmul(document, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46.3462, 47.2246, 50.3101, 50.6814, 50.8784, 52.7157, 50.9930, 48.7507,\n",
       "        46.7364, 45.3866, 46.4260, 48.3621, 47.3853, 45.6089, 49.2549, 46.1162,\n",
       "        49.9744, 48.2812, 46.1806, 48.8712, 48.1342, 46.9126, 43.9128, 46.2380,\n",
       "        48.4052, 47.4188, 47.9374, 47.6596, 47.1907, 51.5551, 50.9233, 51.8367,\n",
       "        47.7746, 49.4366, 47.3272, 49.4876, 52.6799, 51.5581, 51.0627, 45.3904,\n",
       "        46.5788, 47.6160, 47.3691, 50.9880, 48.1312, 56.4669, 44.8512, 45.0554,\n",
       "        45.6391, 48.6505, 45.9068, 51.3187, 50.3830, 49.6979, 49.2297, 49.5543,\n",
       "        43.1299, 45.9802, 46.5043, 46.8194, 49.4834, 45.2461, 48.1840, 49.5698,\n",
       "        45.9641, 47.1943, 48.4989, 48.5921, 44.6718, 46.2350, 49.7938, 50.5609,\n",
       "        51.8542, 51.9708, 50.9324, 53.8752, 46.0186, 49.4153, 47.2280, 46.2088,\n",
       "        49.1650, 50.0264, 46.9737, 47.2297, 43.4965, 48.1582, 50.1927, 50.3261,\n",
       "        49.7891, 46.9157, 46.8041, 46.2184, 50.8193, 45.5546, 45.0694, 45.1955,\n",
       "        48.1497, 51.8516, 45.2988, 46.2651, 48.4599, 54.8071, 48.4204, 43.1981,\n",
       "        47.7136, 46.6263, 49.7787, 49.2237, 47.6856, 46.6582, 53.2626, 48.3748,\n",
       "        47.4581, 46.6816, 47.2966, 48.5344, 50.9711, 45.4077, 47.0811, 45.8983,\n",
       "        46.8367, 47.5591, 47.3520, 47.2899, 48.9465, 53.5073, 46.2169, 46.6709,\n",
       "        46.0134, 44.9005, 50.1700, 49.1171, 49.3313, 47.5944, 45.8658, 47.9531,\n",
       "        48.3108, 49.7049, 47.6261, 46.7928, 50.1519, 44.7346, 47.6189, 47.3087,\n",
       "        48.9379, 48.1848, 48.7363, 47.6107, 47.5900, 44.9585, 47.3909, 48.6636,\n",
       "        50.9085, 49.3284, 50.0344, 47.2744, 45.7426, 46.6969, 48.3073, 44.4170,\n",
       "        46.2000, 48.4030, 47.1904, 47.8771, 49.7528, 46.2636, 44.9165, 44.9492,\n",
       "        47.2680, 50.2378, 48.0879, 48.7208, 46.2033, 45.8586, 46.6148, 45.9459,\n",
       "        43.5910, 44.3993, 47.0302, 44.0335, 52.2231, 48.4243, 43.2413, 51.9617,\n",
       "        48.1531, 45.2894, 46.2035, 47.0955, 49.4928, 50.3792, 50.0227, 50.4911,\n",
       "        47.2128, 48.3057, 48.7277, 49.9801, 51.1948, 48.4444, 43.4085, 50.0380])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_doc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46.3462, 47.2246, 50.3101, 50.6814, 50.8784, 52.7157, 50.9930, 48.7507,\n",
       "        46.7364, 45.3866, 46.4260, 48.3621, 47.3853, 45.6089, 49.2549, 46.1162,\n",
       "        49.9744, 48.2812, 46.1806, 48.8712, 48.1342, 46.9126, 43.9128, 46.2380,\n",
       "        48.4052, 47.4188, 47.9374, 47.6596, 47.1907, 51.5551, 50.9233, 51.8367,\n",
       "        47.7746, 49.4366, 47.3272, 49.4876, 52.6799, 51.5581, 51.0627, 45.3904,\n",
       "        46.5788, 47.6160, 47.3691, 50.9880, 48.1312, 56.4669, 44.8512, 45.0554,\n",
       "        45.6391, 48.6505, 45.9068, 51.3187, 50.3830, 49.6979, 49.2297, 49.5543,\n",
       "        43.1299, 45.9802, 46.5043, 46.8194, 49.4834, 45.2461, 48.1840, 49.5698,\n",
       "        45.9641, 47.1943, 48.4989, 48.5921, 44.6718, 46.2350, 49.7938, 50.5609,\n",
       "        51.8542, 51.9708, 50.9324, 53.8752, 46.0186, 49.4153, 47.2280, 46.2088,\n",
       "        49.1650, 50.0264, 46.9737, 47.2297, 43.4965, 48.1582, 50.1927, 50.3261,\n",
       "        49.7891, 46.9157, 46.8041, 46.2184, 50.8193, 45.5546, 45.0694, 45.1955,\n",
       "        48.1497, 51.8516, 45.2988, 46.2651, 48.4599, 54.8071, 48.4204, 43.1981,\n",
       "        47.7136, 46.6263, 49.7787, 49.2237, 47.6856, 46.6582, 53.2626, 48.3748,\n",
       "        47.4581, 46.6816, 47.2966, 48.5344, 50.9711, 45.4077, 47.0811, 45.8983,\n",
       "        46.8367, 47.5591, 47.3520, 47.2899, 48.9465, 53.5073, 46.2169, 46.6709,\n",
       "        46.0134, 44.9005, 50.1700, 49.1171, 49.3313, 47.5944, 45.8659, 47.9531,\n",
       "        48.3108, 49.7049, 47.6261, 46.7928, 50.1519, 44.7346, 47.6189, 47.3087,\n",
       "        48.9379, 48.1848, 48.7363, 47.6107, 47.5900, 44.9585, 47.3909, 48.6636,\n",
       "        50.9085, 49.3284, 50.0344, 47.2744, 45.7426, 46.6969, 48.3073, 44.4170,\n",
       "        46.2000, 48.4030, 47.1904, 47.8771, 49.7528, 46.2636, 44.9165, 44.9492,\n",
       "        47.2680, 50.2378, 48.0879, 48.7208, 46.2033, 45.8586, 46.6148, 45.9459,\n",
       "        43.5910, 44.3992, 47.0302, 44.0335, 52.2231, 48.4243, 43.2413, 51.9617,\n",
       "        48.1531, 45.2894, 46.2035, 47.0955, 49.4928, 50.3792, 50.0227, 50.4911,\n",
       "        47.2128, 48.3057, 48.7277, 49.9801, 51.1948, 48.4443, 43.4085, 50.0380])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(weight.t(), document[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4790.1016)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(context_doc[0,0], question[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5228.5557)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(context_doc[0,0], question[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 200])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 150])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_doc[:,0,:].t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4790.1021, 4883.9170, 5327.2593,  ..., 4748.8901, 5269.3320,\n",
       "         5032.0112],\n",
       "        [4948.4292, 5033.3193, 5489.5557,  ..., 4899.4922, 5430.6152,\n",
       "         5174.8223],\n",
       "        [4572.0649, 4660.2935, 5068.3086,  ..., 4525.5068, 5028.7559,\n",
       "         4793.7788],\n",
       "        ...,\n",
       "        [5028.6572, 5131.9058, 5588.0142,  ..., 4980.1543, 5533.8848,\n",
       "         5277.4199],\n",
       "        [4574.8687, 4670.8115, 5077.5044,  ..., 4522.1997, 5028.9922,\n",
       "         4788.6475],\n",
       "        [4668.1743, 4752.9648, 5180.3223,  ..., 4614.1733, 5126.5693,\n",
       "         4892.9624]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question[:,0,:].mm(context_doc[:,0,:].t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200, 150])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = context_doc.size()\n",
    "\n",
    "context_doc.view((size[1], size[2], size[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 200])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question.transpose(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix = question.transpose(0, 1).bmm(context_doc.transpose(0,1).transpose(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4790.1021, 4883.9170, 5327.2593,  ..., 4748.8901, 5269.3320,\n",
       "         5032.0112],\n",
       "        [4948.4292, 5033.3193, 5489.5557,  ..., 4899.4922, 5430.6152,\n",
       "         5174.8223],\n",
       "        [4572.0649, 4660.2935, 5068.3086,  ..., 4525.5068, 5028.7559,\n",
       "         4793.7788],\n",
       "        ...,\n",
       "        [5028.6572, 5131.9058, 5588.0142,  ..., 4980.1543, 5533.8848,\n",
       "         5277.4199],\n",
       "        [4574.8687, 4670.8115, 5077.5044,  ..., 4522.1997, 5028.9922,\n",
       "         4788.6475],\n",
       "        [4668.1743, 4752.9648, 5180.3223,  ..., 4614.1733, 5126.5693,\n",
       "         4892.9624]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_doc.transpose(0,1).transpose(1,2) == context_doc.view(size[1], size[2], size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix = question.transpose(0, 1).bmm(context_doc.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 32, 1])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix.sum(1, keepdim=True).permute(2,0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[753692.3125, 776805.0625, 718054.5000, 688292.7500, 750509.6875,\n",
       "         717398.5000, 745473.3125, 790821.6875, 718531.8750, 733282.5000],\n",
       "        [825002.2500, 743449.6250, 743253.5625, 787149.8125, 695025.6875,\n",
       "         781406.3750, 716827.2500, 800148.1875, 756227.0000, 774242.2500],\n",
       "        [756765.0625, 727851.9375, 793576.8125, 772104.8125, 711537.1875,\n",
       "         794268.1875, 761912.8125, 780754.5625, 746204.5000, 797960.0625],\n",
       "        [728362.0625, 722897.6250, 762484.6250, 733160.3125, 778712.1875,\n",
       "         733985.1875, 701824.8125, 806620.2500, 728388.2500, 732860.2500],\n",
       "        [759977.5625, 746989.5000, 755128.8750, 781353.0625, 713528.4375,\n",
       "         705750.0625, 749412.3125, 767647.6875, 761470.0625, 765827.6250],\n",
       "        [762148.0625, 812036.9375, 759314.6875, 781786.0625, 777687.9375,\n",
       "         734953.3125, 730912.8125, 712471.4375, 762822.0625, 723187.1250],\n",
       "        [685153.2500, 734906.8750, 751984.6875, 738572.8125, 738837.5000,\n",
       "         750953.3125, 775621.8125, 720197.2500, 782929.4375, 706852.8125],\n",
       "        [783051.8750, 732522.3125, 747292.3750, 766409.4375, 756449.6875,\n",
       "         774626.0625, 751655.0000, 804282.1875, 762637.7500, 776888.3750],\n",
       "        [773014.7500, 745656.0625, 742031.6250, 700148.8125, 735902.4375,\n",
       "         698261.3125, 743969.0625, 741970.9375, 802695.7500, 816541.2500],\n",
       "        [760807.2500, 772367.6250, 806426.4375, 744114.1250, 707767.3125,\n",
       "         684212.7500, 749112.8125, 779456.3750, 754141.1875, 725344.5000],\n",
       "        [764867.8125, 757051.5000, 750028.2500, 773141.3125, 720186.6875,\n",
       "         792135.8750, 815620.1250, 785449.2500, 747084.0000, 739365.7500],\n",
       "        [725587.0000, 769209.6250, 756644.3750, 771582.0000, 772872.0625,\n",
       "         745804.5625, 740334.6250, 724717.4375, 752126.4375, 783412.1875],\n",
       "        [739114.1875, 839982.0625, 756667.8750, 768396.1875, 814459.9375,\n",
       "         698669.8125, 711881.0000, 793403.7500, 773268.2500, 680749.8750],\n",
       "        [750474.1875, 740527.7500, 763632.8125, 761789.7500, 773928.8750,\n",
       "         721008.6875, 744665.6250, 798708.2500, 719319.3125, 769620.3750],\n",
       "        [807769.0625, 784335.7500, 790806.6250, 748269.1875, 748683.3125,\n",
       "         757383.8750, 765622.1250, 727565.3125, 777403.7500, 779122.0625],\n",
       "        [752051.0000, 713558.5625, 764468.5625, 786795.3750, 763834.4375,\n",
       "         764172.0625, 754095.3750, 779888.6875, 748489.1875, 736655.2500],\n",
       "        [735593.5625, 677087.9375, 724923.0625, 695582.3125, 752062.6875,\n",
       "         731089.1250, 772376.0000, 797850.0625, 730747.0625, 733694.2500],\n",
       "        [693400.0000, 784666.3125, 761905.1875, 762033.8750, 717074.2500,\n",
       "         754636.5625, 709427.6250, 776217.3125, 799665.7500, 762320.3750],\n",
       "        [713113.3750, 703484.6875, 827459.8125, 762435.3125, 778791.6250,\n",
       "         831036.6250, 691071.3750, 737433.0000, 763309.4375, 766207.1250],\n",
       "        [737097.8750, 739748.6250, 767760.8750, 744760.8125, 757817.1875,\n",
       "         741632.7500, 725128.3125, 724984.5000, 769075.5000, 701583.5000],\n",
       "        [705218.9375, 712393.1875, 697877.6250, 737703.5000, 719825.4375,\n",
       "         723631.4375, 773100.0000, 795927.4375, 760013.0625, 779636.5625],\n",
       "        [724813.0625, 739176.6875, 782564.5000, 778998.6250, 754746.9375,\n",
       "         737553.7500, 738621.6875, 727888.1250, 749900.1875, 708810.0000],\n",
       "        [751186.6875, 770275.8750, 821380.5000, 776412.6875, 763994.4375,\n",
       "         770142.1250, 744520.0000, 743696.8750, 768802.6875, 721600.6875],\n",
       "        [780744.5625, 717295.6875, 752749.6875, 761223.0625, 738794.7500,\n",
       "         742747.5625, 787075.9375, 736863.8750, 747592.6250, 748121.8750],\n",
       "        [700164.3125, 795567.1250, 756774.0000, 675848.5000, 710157.0000,\n",
       "         740640.8125, 730422.6875, 758360.4375, 768603.8125, 794198.1875],\n",
       "        [804324.8750, 728287.9375, 770953.9375, 721446.8125, 761405.0000,\n",
       "         743607.0625, 741537.3125, 723610.0000, 743200.5625, 762945.2500],\n",
       "        [776065.9375, 747582.7500, 672161.5625, 794594.3125, 771315.3125,\n",
       "         751175.1250, 801729.6250, 732251.0000, 736461.5000, 783456.6875],\n",
       "        [793652.1875, 773652.6250, 752712.2500, 747782.8750, 800673.7500,\n",
       "         719280.0000, 745149.5000, 720810.2500, 755401.6250, 789372.3750],\n",
       "        [722018.6875, 738093.2500, 757095.6875, 707366.3750, 717397.3750,\n",
       "         763879.1875, 771543.8125, 804278.6875, 817053.6875, 696975.6250],\n",
       "        [715944.3750, 736431.3125, 708860.8125, 815912.9375, 756991.0625,\n",
       "         777461.8750, 752938.9375, 755927.8750, 720310.1875, 776710.3750],\n",
       "        [785025.0000, 761541.1875, 739052.5000, 765540.0000, 764150.6875,\n",
       "         769998.6250, 801883.7500, 739820.9375, 750876.0000, 795131.0625],\n",
       "        [759902.0000, 771681.0625, 801401.9375, 722665.0625, 757373.6250,\n",
       "         781532.8125, 715016.2500, 719020.8125, 805030.5000, 710380.0625]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix.sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6826, 0.1367, 0.2883],\n",
       "        [0.7196, 0.1209, 0.0548]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6826, 0.1367],\n",
       "        [0.2883, 0.7196],\n",
       "        [0.1209, 0.0548]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6826, 0.7196],\n",
       "        [0.1367, 0.1209],\n",
       "        [0.2883, 0.0548]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class TaskSpecificAttention(nn.Module):\n",
    "\tdef __init__(self, input_size, projection_size):\n",
    "\t\tsuper(TaskSpecificAttention, self).__init__()\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.projection_size = projection_size\n",
    "\t\tself.context_vector = torch.randn((1, 1, projection_size), requires_grad=True)\n",
    "\t\tself.input_projection = nn.Tanh(nn.Linear(input_size, projection_size))\n",
    "\t\tself.softmax = nn.Softmax()\n",
    "\n",
    "\tdef forward(self, input_seq):\n",
    "\t\t'''inputs should be [seq_length, batch_size, input_size]'''\n",
    "\t\tvector_attention = self.input_projection(input_seq) # should be [seq_length, batch_size, output_size]\n",
    "\t\tattention_weights = self.softmax((vector_attention * self.context_vector).sum(2, keepdim=True), dim=0) # should be [seq_length, batch_size, 1]\n",
    "\t\treturn attention_weights\n",
    "\n",
    "class BiLinearAttention(nn.Module):\n",
    "\tdef __init__(self, input_size):\n",
    "\t\tsuper(BiLinearAttention, self).__init__()\n",
    "\t\tself.input_size = input_size\n",
    "\n",
    "\t\tself.context_matrix = torch.randn((input_size, input_size), requires_grad=True)\n",
    "\t\tself.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\tdef forward(self, question, document):\n",
    "\t\t'''inputs should be [seq_length, batch_size, input_size]'''\n",
    "\t\tdocument_context = torch.matmul(document, self.context_matrix)\n",
    "\t\tattention_matrix = question.transpose(0, 1).bmm(document_context.permute(1, 2, 0))\n",
    "\t\tattention_weights = self.softmax(attention_matrix.sum(1, keepdim=True).permute(2,0,1))\n",
    "\t\treturn attention_weights\n",
    "\n",
    "\n",
    "class AttentiveReader(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, lstm_layers=1, lstm_bidirectional=True):\n",
    "        super(AttentiveReader, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.question_lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=lstm_layers, bidirectional=lstm_bidirectional)\n",
    "        self.document_lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=lstm_layers, bidirectional=lstm_bidirectional)\n",
    "        self.attention = BiLinearAttention(input_size=hidden_dim * 2 if lstm_bidirectional else 1)\n",
    "\n",
    "    def forward(self, question, document):\n",
    "        question_embedding = self.word_embeddings(question)\n",
    "        document_embedding = self.word_embeddings(document)\n",
    "        print(question_embedding.shape)\n",
    "\n",
    "        question_encoding, _ = self.question_lstm(question_embedding)\n",
    "        document_encoding, _ = self.document_lstm(document_embedding)\n",
    "\n",
    "        attention = self.attention(question_encoding, document_encoding)\n",
    "        print(attention.shape, document_encoding.shape)\n",
    "        output = (attention * document_encoding).sum(2)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = AttentiveReader(100, 100, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = torch.randint(low=0, high=50000, size=((10,32)))\n",
    "document = torch.randint(low=0, high=50000, size=((200,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 100])\n",
      "torch.Size([200, 32, 1]) torch.Size([200, 32, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(question, document).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/16/4d247e27c55a7b6412e7c4c86f2500ae61afcbf5932b9e3491f8462f8d9e/nltk-3.4.4.zip (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 170kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/mohamedkhodeir/anaconda3/envs/deeprl/lib/python3.5/site-packages (from nltk) (1.11.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/mohamedkhodeir/Library/Caches/pip/wheels/41/c8/31/48ace4468e236e0e8435f30d33e43df48594e4d53e367cf061\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.4\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohamedkhodeir/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "print(word_tokenize(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "model = loadGloveModel('data/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(50000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "def corpus_iterator():\n",
    "    for i in corpus:\n",
    "        yield i\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    ">>> print(vectorizer.get_feature_names())\n",
    "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
    ">>> print(X.shape)\n",
    "(4, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
